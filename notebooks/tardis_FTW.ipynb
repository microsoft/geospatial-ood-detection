{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2024 Microsoft Corporation.\n",
    "\n",
    "Licensed under the MIT License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform TARDIS on FTW dataset\n",
    "- Define ID and WILD dataloaders\n",
    "- Form and apply the TARDIS pipeline on the pretrained FTW model\n",
    "- Plot f, g distribution on map\n",
    "- Plot the activation space of g\n",
    "- Plot f, g predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from scipy.stats import skew\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torchgeo.trainers import SemanticSegmentationTask\n",
    "from src.tardis_ftw.data_utils import (\n",
    "    FTWDataModuleOOD,\n",
    "    WILDDataset,\n",
    "    process_ID_dataloader,\n",
    "    process_WILD_dataloader,\n",
    ")\n",
    "from src.tardis_ftw.tardis_wrapper import TARDISWrapper, get_model_layers\n",
    "from src.tardis_ftw.utils import (\n",
    "    calculate_metrics,\n",
    "    extract_data,\n",
    "    load_config,\n",
    "    percentile_stretch,\n",
    "    plot_f_and_g_preds_probab,\n",
    "    plot_g_prob_distribution_w_skewness,\n",
    "    plot_histograms_for_countries,\n",
    "    plot_ID_surrID_surrOOD,\n",
    "    plot_ID_WILD,\n",
    "    plot_tsne,\n",
    "    plot_ftwtest_f1_skew_r2,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration from YAML file\n",
    "config = load_config(config_path=\"../src/tardis_ftw/config.yaml\")\n",
    "\n",
    "# Base directory\n",
    "base_dir = Path(config[\"base_dir\"])\n",
    "\n",
    "# Paths using the base directory\n",
    "model_checkpoint = base_dir / config[\"paths\"][\"model_checkpoint\"]\n",
    "root_folder_torchgeo = base_dir / config[\"paths\"][\"root_folder_torchgeo\"]\n",
    "path_wild_patches = base_dir / config[\"paths\"][\"path_wild_patches\"]\n",
    "\n",
    "# Dataloader parameters\n",
    "batch_size = config[\"dataloader\"][\"batch_size\"]\n",
    "num_workers = config[\"dataloader\"][\"num_workers\"]\n",
    "sample_N_from_each_country = config[\"dataloader\"][\"sample_N_from_each_country\"]\n",
    "all_countries = config[\"dataloader\"][\"all_countries\"]\n",
    "val_countries = config[\"dataloader\"][\"val_countries\"]\n",
    "test_countries = config[\"dataloader\"][\"test_countries\"]\n",
    "target = config[\"dataloader\"][\"target\"]\n",
    "\n",
    "# OOD detector parameters\n",
    "chosen_layer = config[\"ood_detector\"][\"chosen_layer\"]\n",
    "resize_factor = config[\"ood_detector\"][\"resize_factor\"]\n",
    "id_fraction_thr = config[\"ood_detector\"][\"id_fraction_thr\"]\n",
    "n_batches_to_process = config[\"ood_detector\"][\"n_batches_to_process\"]\n",
    "random_state = config[\"ood_detector\"][\"random_state\"]\n",
    "estimators = config[\"ood_detector\"][\"estimators\"]\n",
    "test_size = config[\"ood_detector\"][\"test_size\"]\n",
    "use_optuna = config[\"ood_detector\"][\"use_optuna\"]\n",
    "patch_size = config[\"ood_detector\"][\"patch_size\"]\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Path verification\n",
    "print(f\"Model checkpoint path: {model_checkpoint.resolve()}\")\n",
    "print(f\"Root folder for TorchGeo: {root_folder_torchgeo.resolve()}\")\n",
    "print(f\"Path to wild patches: {path_wild_patches.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the checkpoint to get the hyperparams\n",
    "checkpoint = torch.load(model_checkpoint, map_location=\"cpu\")\n",
    "params = checkpoint[\"hyper_parameters\"]\n",
    "\n",
    "# Ensure compatibility of the checkpoint parameters with the task definition\n",
    "# For example, converting class_weights to a torch.Tensor if required by the model\n",
    "if \"class_weights\" in params and isinstance(params[\"class_weights\"], list):\n",
    "    params[\"class_weights\"] = torch.tensor(params[\"class_weights\"], dtype=torch.float32)\n",
    "\n",
    "# Load the task from the checkpoint\n",
    "task = SemanticSegmentationTask.load_from_checkpoint(\n",
    "    checkpoint_path=model_checkpoint,\n",
    "    map_location=device,\n",
    "    **params  # Use updated params\n",
    ")\n",
    "\n",
    "task.freeze()\n",
    "model = task.model\n",
    "model = model.eval().to(device)\n",
    "\n",
    "layer_names = get_model_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FTWDatamoduleOOD = FTWDataModuleOOD(\n",
    "    root_folder_torchgeo,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    train_countries=all_countries,\n",
    "    val_countries=val_countries,\n",
    "    test_countries=test_countries,\n",
    "    download=True,\n",
    "    sample_N_from_each_country=sample_N_from_each_country,\n",
    "    target=target,\n",
    ")\n",
    "\n",
    "FTWDatamoduleOOD.setup(stage=\"fit\")\n",
    "id_train_dataloader = FTWDatamoduleOOD.train_dataloader()\n",
    "val_dataloader = FTWDatamoduleOOD.val_dataloader()\n",
    "FTWDatamoduleOOD.setup(stage=\"test\")\n",
    "test_dataloader = FTWDatamoduleOOD.test_dataloader()\n",
    "\n",
    "print(\"len train samples\", len(id_train_dataloader.dataset))\n",
    "print(\"len val samples\", len(val_dataloader.dataset))\n",
    "print(\"len test samples\", len(test_dataloader.dataset))\n",
    "print(next(iter(id_train_dataloader))[\"image\"].shape)\n",
    "print(\"DataModule setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WILD Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wild_dataset = WILDGeoTIFFDataset(directory=path_wild_patches)\n",
    "wild_data_loader = DataLoader(wild_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"len(dataset):\", len(wild_data_loader.dataset))\n",
    "print(next(iter(wild_data_loader))[\"image\"].shape)\n",
    "len(wild_dataset.coords), len(wild_dataset.valid_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = int(0.3 * len(id_train_dataloader.dataset))\n",
    "\n",
    "ood_model = TARDISWrapper(\n",
    "    base_model=model,\n",
    "    hook_layer_name=chosen_layer,\n",
    "    main_loader=FTWDatamoduleOOD,\n",
    "    id_loader=id_train_dataloader,\n",
    "    wild_loader=wild_data_loader,\n",
    "    n_batches_to_process=n_batches_to_process,\n",
    "    test_size=test_size,\n",
    "    use_optuna=False,\n",
    "    num_clusters=num_clusters,\n",
    "    M=id_fraction_thr,\n",
    "    random_state=random_state,\n",
    "    n_estimators=estimators,\n",
    "    resize_factor=resize_factor,\n",
    "    patch_size=patch_size,\n",
    "    device=device,\n",
    "    classifier_save_path=\"ood_classifier.pkl\",\n",
    ")\n",
    "\n",
    "print(\"number of ID samples\", len(id_train_dataloader.dataset))\n",
    "print(\"number of WILD samples\", len(wild_data_loader.dataset))\n",
    "print(\"Chosen layer:\", chosen_layer)\n",
    "print(\"Number of clusters:\", num_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply TARDIS:\n",
    "- Compute features\n",
    "- Apply surrogate label assignment \n",
    "- Train the classifier g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if hasattr(ood_model.ood_classifier, \"classes_\"):\n",
    "    print(\"'g' is already loaded.\")\n",
    "    pass\n",
    "else:\n",
    "    print(\"'g' is not loaded.\")\n",
    "    # Compute features\n",
    "    X, y = ood_model.compute_features()\n",
    "    # Feature space clustering\n",
    "    y_clustered = ood_model.feature_space_clustering(X, y)\n",
    "    # Classification\n",
    "    metrics = ood_model.g_classification(X, y_clustered)\n",
    "    # Print metrics if training a classifier\n",
    "    print(metrics[\"accuracy\"])\n",
    "    print(metrics[\"classification_report\"])\n",
    "    print(metrics[\"fpr95\"])\n",
    "    print(metrics[\"roc_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ID_all = process_ID_dataloader(\n",
    "    id_train_dataloader,\n",
    "    ood_model,\n",
    "    return_batch=True,\n",
    "    return_f_pred=True,\n",
    "    return_g_pred=True,\n",
    "    return_thresholded_g_pred=False,\n",
    "    return_coords=True,\n",
    "    return_masks=True,\n",
    "    upsample=True,\n",
    "    max_batches=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect WILD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WILD_all = process_WILD_dataloader(\n",
    "    wild_data_loader,\n",
    "    ood_model,\n",
    "    return_batch=True,\n",
    "    return_f_pred=True,\n",
    "    return_g_pred=True,\n",
    "    return_thresholded_g_pred=False,\n",
    "    return_coords=True,\n",
    "    upsample=True,\n",
    "    max_batches=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if y is not None:\n",
    "        y_uniq, y_counts = np.unique(y, return_counts=True)\n",
    "        print(\n",
    "            \"There are {unique} unique clusters with counts {counts}\".format(\n",
    "                unique=len(y_uniq), counts=dict(zip(y_uniq, y_counts))\n",
    "            )\n",
    "        )\n",
    "        print(\"X .shape:\", X.shape)\n",
    "        y_clustered_uniq, y_clustered_counts = np.unique(\n",
    "            y_clustered, return_counts=True\n",
    "        )\n",
    "        print(\n",
    "            \"There are {unique} unique clusters with counts {counts}\".format(\n",
    "                unique=len(y_clustered_uniq),\n",
    "                counts=dict(zip(y_clustered_uniq, y_clustered_counts)),\n",
    "            )\n",
    "        )\n",
    "except NameError:\n",
    "    print(\"Variable 'y' or 'y_clustered' is not defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the activation space: \"X\" in 2D, labelled with y (ID/WILD labels) and y_clustered (Surrogate ID and Surrogate OOD labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plot_tsne(X, y, y_clustered)\n",
    "\n",
    "except NameError:\n",
    "    print(\"Variable 'y' or 'y_clustered' is not defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot on map: ID and WILD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ID_WILD(\n",
    "    ID_all,\n",
    "    WILD_all,\n",
    "    save=True,\n",
    "    file_format=\"png\",\n",
    "    dpi=100,\n",
    "    filepath=\"./plots\",\n",
    "    filename=\"on_map_id_wild\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Plot on map: ID and WILD breakdown into surrogate ID and surrogate OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ID_surrID_surrOOD(\n",
    "    WILD_all,\n",
    "    ID_all,\n",
    "    save=True,\n",
    "    file_format=\"png\",\n",
    "    dpi=100,\n",
    "    filepath=\"./plots\",\n",
    "    filename=\"on_map_id_surrID_surrOOD\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g(WILD) probabilities in a Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_prob = skew(WILD_all[\"g_pred_probs\"])\n",
    "print(\"Skewness of g_pred over WILD data\", skew_prob)\n",
    "\n",
    "plot_g_prob_distribution_w_skewness(\n",
    "    WILD_all[\"g_pred_probs\"], suffix=\"WILD\", skewness_value=skew_prob, save_plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g and f(FTW_{train}^country[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloader_factory = {}\n",
    "max_batches = None\n",
    "batch_size = 1\n",
    "\n",
    "for country in all_countries:\n",
    "    FTWDatamoduleOOD = FTWDataModuleOOD(\n",
    "        root_folder_torchgeo,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        train_countries=None,\n",
    "        val_countries=None,\n",
    "        test_countries=country,\n",
    "        download=False,\n",
    "        sample_N_from_each_country=sample_N_from_each_country,\n",
    "        target=target,\n",
    "    )\n",
    "\n",
    "    FTWDatamoduleOOD.setup(stage=\"test\")\n",
    "    test_dataloader = FTWDatamoduleOOD.test_dataloader()\n",
    "    dataloader_factory[country] = test_dataloader\n",
    "\n",
    "country_results = {}\n",
    "metrics_dict = {}\n",
    "\n",
    "for country in tqdm.tqdm(all_countries):\n",
    "    print(\"Country:\", country)\n",
    "\n",
    "    testset_id_dataloader = dataloader_factory[country]\n",
    "\n",
    "    return_f_pred = True\n",
    "    return_g_pred = True\n",
    "    return_thresholded_g_pred = False\n",
    "    return_coords = False\n",
    "    return_masks = True\n",
    "    upsample = True\n",
    "    max_batches = max_batches\n",
    "\n",
    "    ID_all = process_ID_dataloader(\n",
    "        testset_id_dataloader,\n",
    "        ood_model,\n",
    "        return_f_pred=return_f_pred,\n",
    "        return_g_pred=return_g_pred,\n",
    "        return_thresholded_g_pred=return_thresholded_g_pred,\n",
    "        return_coords=return_coords,\n",
    "        return_masks=return_masks,\n",
    "        upsample=upsample,\n",
    "        max_batches=max_batches,\n",
    "    )\n",
    "\n",
    "    f_preds_single_channel = ID_all[\"f_preds\"]\n",
    "    g_pred_probs_testsetid = ID_all[\"g_pred_probs\"]\n",
    "    true_masks_all = ID_all[\"masks\"]\n",
    "\n",
    "    metrics = calculate_metrics(true_masks_all, f_preds_single_channel)\n",
    "\n",
    "    country_results[country] = {\n",
    "        \"f_preds_testsetid\": f_preds_single_channel,\n",
    "        \"g_pred_probs_testsetid\": g_pred_probs_testsetid,\n",
    "        \"true_masks\": true_masks_all,\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "\n",
    "    # Clean up\n",
    "    del f_preds_single_channel, g_pred_probs_testsetid, true_masks_all\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hist for all Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_histograms_for_countries(country_results, metric=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score vs. OOD score probability Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_data(country_results)\n",
    "\n",
    "df[\"country\"] = df[\"country\"].str.strip().str.lower()\n",
    "\n",
    "countries_to_remove = [\"rwanda\", \"kenya\", \"india\", \"brazil\"]\n",
    "df = df[~df[\"country\"].isin(countries_to_remove)]\n",
    "\n",
    "df[\"country\"] = df[\"country\"].str.replace(\"_\", \" \").str.title()\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "plot_ftwtest_f1_skew_r2(df, save_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input, g, and f preds of 10 Percentiles: lowest, mid and top. Plot and save them all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the array and get the corresponding indexes\n",
    "sorted_indexes = np.argsort(WILD_all[\"g_pred_probs\"])\n",
    "\n",
    "# Determine the percentile ranges\n",
    "n = len(WILD_all[\"g_pred_probs\"])\n",
    "lowest_10_percentile_indexes = sorted_indexes[: int(0.1 * n)]\n",
    "mid_10_percentile_start = int(0.45 * n)\n",
    "mid_10_percentile_end = int(0.55 * n)\n",
    "mid_10_percentile_indexes = sorted_indexes[\n",
    "    mid_10_percentile_start:mid_10_percentile_end\n",
    "]\n",
    "top_10_percentile_indexes = sorted_indexes[-int(0.1 * n) :]\n",
    "\n",
    "print(\"Indexes of the lowest 10 percentile values:\", lowest_10_percentile_indexes)\n",
    "print(\"Indexes of the middle 10 percentile values:\", mid_10_percentile_indexes)\n",
    "print(\"Indexes of the top 10 percentile values:\", top_10_percentile_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(lowest_10_percentile_indexes)\n",
    "coord = WILD_all[\"coords\"][idx]\n",
    "g_pred_prob_wild = WILD_all[\"g_pred_probs\"][idx]\n",
    "\n",
    "window_a = percentile_stretch(WILD_all[\"batch\"][idx, :3, :, :].permute(1, 2, 0))\n",
    "window_b = percentile_stretch(WILD_all[\"batch\"][idx, 4:-1, :, :].permute(1, 2, 0))\n",
    "\n",
    "f_pred_permuted = WILD_all[\"f_preds\"][idx]\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "fname = f\"{g_pred_prob_wild}_WILD_{idx}_{timestamp}.png\"\n",
    "print(\"OOD Score\", g_pred_prob_wild)\n",
    "plot_f_and_g_preds_probab(window_a, window_b, g_pred_prob_wild, f_pred_permuted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_dict = {\n",
    "    \"lowest_10\": lowest_10_percentile_indexes,\n",
    "    \"mid_10\": mid_10_percentile_indexes,\n",
    "    \"top_10\": top_10_percentile_indexes,\n",
    "}\n",
    "\n",
    "num_samples_to_process = len(percentiles_dict[\"lowest_10\"])\n",
    "\n",
    "for perc_name, percentile_idx in percentiles_dict.items():\n",
    "    sample_count = 0\n",
    "    for idx in percentile_idx:\n",
    "        if sample_count >= num_samples_to_process:\n",
    "            break\n",
    "\n",
    "        coord = WILD_all[\"coords\"][idx]\n",
    "        g_pred_prob_wild = WILD_all[\"g_pred_probs\"][idx]\n",
    "\n",
    "        window_a = percentile_stretch(WILD_all[\"batch\"][idx, :3, :, :].permute(1, 2, 0))\n",
    "        window_b = percentile_stretch(\n",
    "            WILD_all[\"batch\"][idx, 4:-1, :, :].permute(1, 2, 0)\n",
    "        )\n",
    "\n",
    "        f_pred_permuted = WILD_all[\"f_preds\"][idx]\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        fname = f\"{perc_name}_{g_pred_prob_wild}_WILD_{idx}_{timestamp}.png\"\n",
    "\n",
    "        plot_f_and_g_preds_probab(\n",
    "            window_a,\n",
    "            window_b,\n",
    "            g_pred_prob_wild,\n",
    "            f_pred_permuted,\n",
    "            \"./preds_percentile\",\n",
    "            fname,\n",
    "        )\n",
    "\n",
    "        sample_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ood)",
   "language": "python",
   "name": "ood"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
